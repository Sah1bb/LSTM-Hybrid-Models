import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential, Model
from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Flatten, Input, concatenate
from keras.optimizers import Adam
import yfinance as yf
import math
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import os

# MAPE hesaplama fonksiyonu
def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Mevcut çalışma dizinini kontrol etme
print("Mevcut Çalışma Dizini:", os.getcwd())

# Veri toplama (yfinance kütüphanesinden verileri alma)
print("Veri toplama başlıyor...")
data = yf.download('ARCLK.IS', start='2020-01-01', end='2023-01-01')
print("Veri toplama tamamlandı.")

# Ham veriler tablosu
ham_veriler = data[['Open', 'High', 'Low', 'Close', 'Volume']]
ham_veriler.reset_index(inplace=True)
print("Ham veriler tablosu oluşturuldu.")

# Ham verileri CSV dosyasına kaydetme
ham_veriler.to_csv('ham_veriler.csv', index=False)
print("Ham veriler CSV dosyasına kaydedildi.")

# Ham verilerden birkaç örnek gösterme
print("Ham Veriler (Örnek):")
print(ham_veriler.head())

# Veri ön işleme
print("Veri ön işleme başlıyor...")
features = ['Open', 'High', 'Low', 'Close', 'Volume']
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[features])
print("Veri ön işleme tamamlandı.")

# İşlenmiş veriler tablosu
islenmis_veriler = pd.DataFrame(scaled_data, columns=features)

# İşlenmiş verileri CSV dosyasına kaydetme
islenmis_veriler.to_csv('islenmis_veriler.csv', index=False)
print("İşlenmiş veriler CSV dosyasına kaydedildi.")

# İşlenmiş verilerden birkaç örnek gösterme
print("İşlenmiş Veriler (Örnek):")
print(islenmis_veriler.head())

# Eğitim ve test setlerine ayırma
print("Eğitim ve test setlerine ayırma başlıyor...")
train_size = int(len(scaled_data) * 0.8)
test_size = len(scaled_data) - train_size
train_data, test_data = scaled_data[0:train_size], scaled_data[train_size:len(scaled_data)]
print("Eğitim ve test setlerine ayırma tamamlandı.")

# Eğitim ve test setlerinin boyutlarını yazdırma
print(f"Train data shape: {train_data.shape}")
print(f"Test data shape: {test_data.shape}")

# LSTM ve CNN için veri setini hazırlama
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step)]
        X.append(a)
        Y.append(dataset[i + time_step, 3])
    return np.array(X), np.array(Y)

print("Veri seti oluşturma başlıyor...")
time_step = 50  # Zaman adımı
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)
print("Veri seti oluşturma tamamlandı.")

# Eğitim ve test veri setlerinin boyutlarını yazdırma
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], len(features))
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], len(features))

# Hibrit model geliştirme
print("Hibrit model geliştirme başlıyor...")
input_layer = Input(shape=(time_step, len(features)))

# CNN Katmanları
cnn_out = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)
cnn_out = MaxPooling1D(pool_size=2)(cnn_out)
cnn_out = Flatten()(cnn_out)

# LSTM Katmanları
lstm_out = LSTM(units=100, return_sequences=True)(input_layer)
lstm_out = Dropout(0.2)(lstm_out)
lstm_out = LSTM(units=100, return_sequences=False)(lstm_out)
lstm_out = Dropout(0.2)(lstm_out)

# CNN ve LSTM Katmanlarının Birleştirilmesi
combined = concatenate([cnn_out, lstm_out])
combined = Dense(units=50)(combined)
output_layer = Dense(units=1)(combined)

# Modeli oluşturma ve derleme
model = Model(inputs=input_layer, outputs=output_layer)
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
print("Hibrit model oluşturuldu ve derlendi.")

# Modeli eğitme
print("Model eğitimi başlıyor...")
history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.1, verbose=1)
print("Model eğitimi tamamlandı.")

# Tahmin yapma ve performansı değerlendirme
print("Tahmin yapma ve performansı değerlendirme başlıyor...")
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)
print("Tahmin yapma ve performansı değerlendirme tamamlandı.")

# Sadece kapanış fiyatları ölçeklendirmesini tersine çevirme
print("Sonuçları tersine çevirme başlıyor...")
train_predict_close = scaler.inverse_transform(np.concatenate((train_predict, np.zeros((train_predict.shape[0], len(features) - 1))), axis=1))[:, 0]
test_predict_close = scaler.inverse_transform(np.concatenate((test_predict, np.zeros((test_predict.shape[0], len(features) - 1))), axis=1))[:, 0]
y_train_close = scaler.inverse_transform(np.concatenate((y_train.reshape(-1, 1), np.zeros((y_train.shape[0], len(features) - 1))), axis=1))[:, 0]
y_test_close = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], len(features) - 1))), axis=1))[:, 0]
print("Sonuçları tersine çevirme tamamlandı.")

# Performans metriklerini hesaplama
print("Performans metrikleri hesaplanıyor...")
train_rmse = math.sqrt(mean_squared_error(y_train_close, train_predict_close))
test_rmse = math.sqrt(mean_squared_error(y_test_close, test_predict_close))
train_mae = mean_absolute_error(y_train_close, train_predict_close)
test_mae = mean_absolute_error(y_test_close, test_predict_close)
train_mape = mean_absolute_percentage_error(y_train_close, train_predict_close)
test_mape = mean_absolute_percentage_error(y_test_close, test_predict_close)
train_r2 = r2_score(y_train_close, train_predict_close)
test_r2 = r2_score(y_test_close, test_predict_close)
train_mse = mean_squared_error(y_train_close, train_predict_close)
test_mse = mean_squared_error(y_test_close, test_predict_close)

# Doğruluk oranı hesaplama (1 - MAE / ortalama gerçek fiyat)
accuracy = 1 - (test_mae / np.mean(y_test_close))
print(f"Accuracy: {accuracy * 100:.2f}%")

# Performans metriklerini tek bir tabloya toplama
metrics = {
    'Metric': ['RMSE', 'MAE', 'MAPE', 'R2', 'MSE'],
    'Train': [train_rmse, train_mae, train_mape, train_r2, train_mse],
    'Test': [test_rmse, test_mae, test_mape, test_r2, test_mse]
}

metrics_df = pd.DataFrame(metrics)
print(metrics_df)

# Performans metriklerini CSV dosyasına kaydetme
metrics_df.to_csv('performans_metrikleri.csv', index=False)
print("Performans metrikleri CSV dosyasına kaydedildi.")

# Eğitim tahminleri tablosu
print("Eğitim tahminleri tablosu oluşturuluyor...")
dates = pd.Series(data.index)
egitim_sonuc = pd.DataFrame({
    'Tarih': dates[time_step:time_step + len(train_predict_close)].tolist(),
    'Gerçek Kapanış Fiyatı': y_train_close,
    'Eğitim Tahminleri': train_predict_close
})

# Eğitim sonuçlarını CSV dosyasına kaydetme
egitim_sonuc.to_csv('egitim_sonuc_verileri.csv', index=False)
print("Eğitim tahminleri CSV dosyasına kaydedildi.")

# Eğitim sonuçlarından birkaç örnek gösterme
print("Eğitim Sonuç Verileri (Örnek):")
print(egitim_sonuc.head(10))

# Test tahminleri tablosu
print("Test tahminleri tablosu oluşturuluyor...")
test_sonuc = pd.DataFrame({
    'Tarih': dates[len(scaled_data) - len(test_predict_close):].tolist(),
    'Gerçek Kapanış Fiyatı': y_test_close,
    'Test Tahminleri': test_predict_close
})

# Test sonuçlarını CSV dosyasına kaydetme
test_sonuc.to_csv('test_sonuc_verileri.csv', index=False)
print("Test tahminleri CSV dosyasına kaydedildi.")

# Test sonuçlarından birkaç örnek gösterme
print("Test Sonuç Verileri (Örnek):")
print(test_sonuc.head(10))

# Tahminleri görselleştirme
print("Tahminleri görselleştirme başlıyor...")
plt.figure(figsize=(14, 5))
plt.plot(dates, data['Close'], label='Gerçek Fiyatlar')
plt.plot(dates[time_step:time_step + len(train_predict_close)], train_predict_close, label='Eğitim Tahminleri')
plt.plot(dates[len(scaled_data) - len(test_predict_close):], test_predict_close, label='Test Tahminleri')
plt.xlabel('Tarih')  # X ekseni etiketi
plt.ylabel('Fiyat')  # Y ekseni etiketi
plt.title(f'AKBNK.IS Hisse Senedi Fiyat Tahmini\nTime Step: {time_step}\nDoğruluk Oranı: {accuracy * 100:.2f}%')
plt.legend()
plt.show()

# Doğrulama kaybı sonuçları görselleştirme
print("Doğrulama kaybı sonuçları görselleştirme başlıyor...")
plt.figure(figsize=(14, 5))
plt.plot(history.history['loss'], label='Eğitim Kaybı')
plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')
plt.xlabel('Epoch')
plt.ylabel('Kayıp')
plt.title('Eğitim ve Doğrulama Kaybı')
plt.legend()
plt.show()

print("Gerçek ve tahmin edilen fiyatların görselleştirilmesi başlıyor...")
plt.figure(figsize=(14, 5))
plt.plot(dates, data['Close'], label='Gerçek Fiyatlar')
plt.plot(dates[time_step:time_step + len(train_predict_close)], train_predict_close, label='Eğitim Tahminleri')
plt.plot(dates[len(scaled_data) - len(test_predict_close):], test_predict_close, label='Test Tahminleri')
plt.xlabel('Tarih')
plt.ylabel('Fiyat')
plt.title('Gerçek ve Tahmin Edilen AKBNK.IS Hisse Senedi Fiyatları')
plt.legend()
plt.show()
